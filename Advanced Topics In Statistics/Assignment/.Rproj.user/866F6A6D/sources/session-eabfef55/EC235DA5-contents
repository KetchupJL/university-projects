library(gt)
library(dplyr)
library(tibble)

# Process and create gt table
gelman.diag(jagsfit.mcmc, multivariate = FALSE)$psrf %>%
  as.data.frame() %>%
  tibble::rownames_to_column(var = "Parameter") %>%
  rename_with(~ gsub("\\s+", "_", .x)) %>% # Replace any spaces in column names
  filter(Parameter %in% c("mu", "beta", "tau", "lambda", "sigma_y2", "sigma_alpha2")) %>%
  select(Parameter, Point_est., Upper_C.I.) %>% # Use updated column names
  gt() %>%
  tab_header(title = "Gelman-Rubin Statistics for Key Parameters") %>%
  fmt_number(
    columns = c("Point_est.", "Upper_C.I."), # Updated column names here
    decimals = 3
  ) %>%
  cols_label(
    Point_est. = "Point Estimate",
    Upper_C.I. = "Upper CI"
  ) %>%
  tab_options(
    table.font.size = px(14),
    heading.title.font.size = px(16),
    heading.title.font.weight = "bold"
  )













mdl <- svm(yTrain~., data = df, kernel = "radial")

print(mdl)

plot(mdl, df, X2 ~ X1) # X1 on x-axis, X2 on y-axis

# Test model on testing data
yTestPred <- predict(mdl, newdata=xTest)
# yTestPred <- mdl %>% predict(xTest) 
confusionMatrix(yTestPred, yTest) # predicted/true



mdl <- train(x=xTrain,y=yTrain, 
             method = "svmLinear",
             trControl = trainControl("cv", number = 5),
             tuneGrid = expand.grid(C = seq(0, 2, length = 20)))


# Plot model accuracy vs different values of Cost
plot(mdl)
# Print the best tuning parameter C that maximises model accuracy
mdl$bestTune